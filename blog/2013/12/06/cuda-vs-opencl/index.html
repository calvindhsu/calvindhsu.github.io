
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>CUDA vs OpenCL Development Experience on an NVIDIA GPU - visual output</title>
  <meta name="author" content="Calvin Hsu">

  
  <meta name="description" content="I had to make a choice as to what GPGPU API to use for my GPU path tracer. I read sources like CUDA Vs OpenCL: Which should I use and decided &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://calvindhsu.github.io/blog/2013/12/06/cuda-vs-opencl/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="visual output" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans+Caption:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- Load jQuery -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript"></script>
<script type="text/javascript">
    jQuery.noConflict(); // ender.js conflicts with jQuery
</script>
 
<!-- Load FancyBox -->
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" />
<script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>
 
<!-- Fix FancyBox style for OctoPress -->
<style type="text/css">
  .fancybox-wrap { position: fixed !important; }
  .fancybox-opened {
    -webkit-border-radius: 4px !important;
       -moz-border-radius: 4px !important;
            border-radius: 4px !important;
  }
  .fancybox-close, .fancybox-prev span, .fancybox-next span {
    background-color: transparent !important;
    border: 0 !important;
  }
</style>

 
<!-- Custom Scripts -->
<script language="Javascript" type="text/javascript">
    // ender.js gobbles jQuery's ready event: Use ender.js $ instead
    $(document).ready(function() {
                    jQuery(".fancybox").fancybox();
                        });
</script>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-46211723-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">visual output</a></h1>
  
    <h2>journey of a game and graphics developer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:calvindhsu.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/about">About</a></li>
  <li><a href="/projects">Projects</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="http://www.linkedin.com/in/calvinhsu">Linkedin</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">CUDA vs OpenCL Development Experience on an NVIDIA GPU</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-06T14:01:48-08:00" pubdate data-updated="true">Dec 6<span>th</span>, 2013</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>I had to make a choice as to what GPGPU API to use for my GPU path tracer. I read sources like <a href="http://wiki.tiker.net/CudaVsOpenCL">CUDA Vs OpenCL: Which should I use</a> and decided initially that OpenCL would be the right choice: support an open standard which would see wider and wider adoption and gain experience with the API. However, I found along the way, the path of least resistance brought me to CUDA.</p>

<p>Big caveat here: I approached this choice as something to use for my personal, learning project with no need to ship a commercial product.</p>

<h3>What&rsquo;s inside my machine?</h3>

<p>I started out basing my choice off of the GPU I had already, since I wasn&rsquo;t ready to shell out money for a new card. Obviously if you have an AMD card there&rsquo;s no choice (also good luck if you want to develop on Linux, the drivers <a href="https://wiki.archlinux.org/index.php/AMD_Catalyst">are not well regarded by the community</a>).</p>

<p>So in my case I did have a choice with my 2 year old NVIDIA Geforce 560Ti (Fermi). This post documents experience with the tool support, build system, and language features.</p>

<!-- more -->


<h2>Tools</h2>

<p>GPU tool support has always been vendor specific i.e. Nsight vs CodeXL (previously gDebugger, AMD purchased Graphic Remedy), and FX Composer vs RenderMonkey. For GPGPU computing there&rsquo;s the additional factor that CUDA is NVIDIA&rsquo;s proprietary technology, and this appears to motivate some uneven support.</p>

<h3>NVIDIA Nsight (Eclipse Edition v5.5.0): CUDA only <a href="http://www.nvidia.com/object/nsight.html">Official Site</a></h3>

<p>NVIDIA Nsight doesn&rsquo;t have any support for OpenCL development. I&rsquo;ve only tested out the Eclipse edition at the time of this writing, and it lacks, well, everything:</p>

<ul>
<li>No OpenCL syntax highlighting</li>
<li>Inability to profile OpenCL calls / kernel performance</li>
<li>Inability to debug OpenCL kernels</li>
</ul>


<p>This was a pretty big disappointment, I was really looking forward to at least seeing some performance traces for my program. At least that would help reveal at a glance where the time is being spent (i.e. memory transfers, compute, CPU).</p>

<p><strong>Workaround: Lack of Syntax Highlighting</strong></p>

<p>Because OpenCL&rsquo;s C is similar, Google reveals that a lot of people end up designating cl files as C files, then creating a dummy header file that is included in .cl code, something like:</p>

<figure class='code'><figcaption><span>cl_ignores.h</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="cp">#define __kernel</span>
</span><span class='line'><span class="cp">#define __global</span>
</span><span class='line'><span class="cp">#define __local</span>
</span><span class='line'><span class="cp">#define __constant</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Warning: CUDA kernel debugging requires 2 GPUs or SM3.5</strong></p>

<p>One unfortunate discovery was finding out that kernel debugging requires a 2nd GPU or a SM3.5+ GPU of which there are currently a handful of models. See <a href="http://www.youtube.com/watch?v=nKKLqc2TgsI">this demonstration</a>.</p>

<h3>AMD CodeXL <a href="http://developer.amd.com/tools-and-sdks/heterogeneous-computing/codexl/">Official Site</a></h3>

<p>I evaluated CodeXL for use with NVIDIA hardware on a Linux machine and it <em>does</em> log and report OpenCL calls and errors, but it is not able to debug or profile.</p>

<h3>CUDA only: printf support</h3>

<p>With an inability to use a debugger, one would naturally rely on print to log debug information. However, NVIDIA drivers only support OpenCL 1.1, so printf isn&rsquo;t supported. This support is enabled via vendor extensions, but I cannot find such an OpenCL extension for NVIDIA GPUs.</p>

<p>Funny enough (NVIDIA&rsquo;s priorities are not hidden), CUDA has this function built-in, and it works on the same hardware.</p>

<p><strong>Aside: Why is it important to have printf for GPU development?</strong></p>

<p>Some might argue: don&rsquo;t waste your time, printf isn&rsquo;t useful for debugging, you should write tests or examine that value of output when read back on the CPU.</p>

<p>I believe some of these opinions have to do with the noise of too many inputs. After all if you put in 1 printf into your kernel but your kernels runs 1k threads in parallel you will get so much extra data (Warning: don&rsquo;t do this with 1 GPU since you&rsquo;ll freeze up the driver!).</p>

<p>I argue that it&rsquo;s still useful provided you are able to limit your input sizes. This was a process that I used in my own development process: see a bad pixel, limit rendering to that 1 pixel, use printfs to output debug information to determine where GPU code was failing.</p>

<p>Combine that with the fact that GPU programs are becoming increasingly complicated. Aila &amp; Laine&rsquo;s purportedly state of the art <a href="https://code.google.com/p/understanding-the-efficiency-of-ray-traversal-on-gpus/">GPU ray traversal kernels</a> involves several nested while loops, a stack 32 frames deep, compact data structures with precomputed values. It would be extremely tedious to debug without having some sort of intermediate output besides ray hit / not-hit.</p>

<h3>Build support: CUDA compiles kernel code</h3>

<p>This not only makes you avoid the fuss of dealing with loading text from file and giving your errors at build time, but it makes it easier to share header files between host and device code. This is useful for declaring types that need to be passed between host and device in a shared header file.</p>

<p><strong>CUDA and C++11 with CMake</strong></p>

<p>In my project I encountered some complications with incorporating CUDA and C++11 code. The problem is that CUDA&rsquo;s host compiler is older, and won&rsquo;t compile the latest GCC 4.8 headers that are on my system. The solution is to separate CUDA code into a self contained library, and then link it with the main binary.</p>

<p>Recent versions of CMake already includes a FindCUDA.cmake library written by James Bigler. By default this will propagate your host compiler flags to the NVIDIA C++ compiler. If you&rsquo;re using <code>-std=c++11</code> then you might get an error like this:</p>

<pre><code>/opt/cuda/bin/nvcc /home/calvin/Projects/spbr/spbr/cudakernels/src/bvh_intersect.cu -c -o /home/calvin/Projects/spbr-build2/spbr/cudakernels/CMakeFiles/cudakernels.dir/src/./cudakernels_generated_bvh_intersect.cu.o -ccbin /usr/bin/cc -m64 -D__CL_ENABLE_EXCEPTIONS -Xcompiler ,\"-std=c++11\",\"-g\",\"-Wall\",\"-g\" --gpu-architecture sm_21 -DNVCC -I/opt/cuda/include -I/opt/cuda/include
/usr/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include/stddef.h(432): error: identifier "nullptr" is undefined

/usr/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include/stddef.h(432): error: expected a ";"

/usr/include/c++/4.8.2/x86_64-unknown-linux-gnu/bits/c++config.h(190): error: expected a ";"

/usr/include/c++/4.8.2/exception(63): error: expected a ";"

/usr/include/c++/4.8.2/exception(68): error: expected a ";"

/usr/include/c++/4.8.2/exception(76): error: expected a ";"

/usr/include/c++/4.8.2/exception(83): error: expected a ";"

/usr/include/c++/4.8.2/exception(93): error: expected a "{"
</code></pre>

<p>This is caused by the NVIDIA compiler (nvcc) getting c++11 flags and being able to compile the standard headers. To fix, add the following line to your <code>CMakeLists.txt</code></p>

<figure class='code'><figcaption><span>Getting CUDA to compile with C++11 in CMake&#8220;`</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='cmake'><span class='line'><span class="nb">set</span><span class="p">(</span><span class="s">CUDA_PROPAGATE_HOST_FLAGS</span> <span class="s">OFF</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>OpenCL Semi-workaround 1: Includes by prepending source strings</strong></p>

<p>You can get around lack of include support by prepending header files to your OpenCL source in your host code. But this also messy since then you need a build mechanism to include shared header files as text.</p>

<p><strong>OpenCL Semi-Workaround 2: Auto-convert cl source files to cpp string</strong></p>

<p>The guys who work on <a href="http://www.luxrender.net">Luxrender GPU</a> cleverly made their build system take *.cl files and insert them as strings in .cpp files. This nicety removes the pain of resource managing and loading files from source. Here&rsquo;s a CMake function from their build set-up:</p>

<figure class='code'><figcaption><span>KernelPreprocess.cmake</span><a href='http://www.luxrender.net'>link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='cmake'><span class='line'><span class="nb">FUNCTION</span><span class="p">(</span><span class="s">PreprocessOCLKernel</span> <span class="s">NAMESPACE</span> <span class="s">KERNEL</span> <span class="s">SRC</span> <span class="s">DST</span><span class="p">)</span>
</span><span class='line'>  <span class="nb">MESSAGE</span><span class="p">(</span><span class="s">STATUS</span> <span class="s2">&quot;Preprocessing OpenCL kernel: &quot;</span> <span class="o">${</span><span class="nv">SRC</span><span class="o">}</span> <span class="s2">&quot; =&gt; &quot;</span> <span class="o">${</span><span class="nv">DST</span><span class="o">}</span> <span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="nb">IF</span><span class="p">(</span><span class="s">WIN32</span><span class="p">)</span>
</span><span class='line'>      <span class="nb">add_custom_command</span><span class="p">(</span>
</span><span class='line'>          <span class="s">OUTPUT</span> <span class="o">${</span><span class="nv">DST</span><span class="o">}</span>
</span><span class='line'>          <span class="s">COMMAND</span> <span class="s">echo</span> <span class="s2">&quot;#include &lt;string&gt;&quot;</span> <span class="s">&gt;</span> <span class="o">${</span><span class="nv">DST</span><span class="o">}</span>
</span><span class='line'>          <span class="s">COMMAND</span> <span class="s">echo</span> <span class="s">namespace</span> <span class="o">${</span><span class="nv">NAMESPACE</span><span class="o">}</span> <span class="s2">&quot;{ namespace ocl {&quot;</span> <span class="s">&gt;&gt;</span> <span class="o">${</span><span class="nv">DST</span><span class="o">}</span>
</span><span class='line'>          <span class="s">COMMAND</span> <span class="s">echo</span> <span class="s">std::string</span> <span class="s">KernelSource_PathOCL_</span><span class="o">${</span><span class="nv">KERNEL</span><span class="o">}</span> <span class="s">=</span> <span class="s">&gt;&gt;</span> <span class="o">${</span><span class="nv">DST</span><span class="o">}</span>
</span><span class='line'><span class="c"># TODO: this code need to be update in order to replace &quot; char with \&quot; (i.e. sed &#39;s/&quot;/\\&quot;/g&#39;)</span>
</span><span class='line'>          <span class="s">COMMAND</span> <span class="s">for</span> <span class="s">/F</span> <span class="s">\&quot;usebackq</span> <span class="s">tokens=*\</span><span class="s2">&quot; %%a in (${SRC}) do echo \&quot;</span><span class="s">%%a\\n\</span><span class="s2">&quot; &gt;&gt; ${DST}</span>
</span><span class='line'><span class="s2">         COMMAND echo &quot;</span><span class="s">;</span> <span class="s">}</span> <span class="s">}</span><span class="s2">&quot; &gt;&gt; ${DST}</span>
</span><span class='line'><span class="s2">         MAIN_DEPENDENCY ${SRC}</span>
</span><span class='line'><span class="s2">     )</span>
</span><span class='line'><span class="s2"> ELSE(WIN32)</span>
</span><span class='line'><span class="s2">     add_custom_command(</span>
</span><span class='line'><span class="s2">         OUTPUT ${DST}</span>
</span><span class='line'><span class="s2">         COMMAND echo \&quot;</span><span class="s">\#include</span> <span class="s">&lt;string&gt;\</span><span class="s2">&quot; &gt; ${DST}</span>
</span><span class='line'><span class="s2">         COMMAND echo namespace ${NAMESPACE} \&quot;</span><span class="s">{</span> <span class="s">namespace</span> <span class="s">ocl</span> <span class="s">{\</span><span class="s2">&quot; &gt;&gt; ${DST}</span>
</span><span class='line'><span class="s2">         COMMAND echo &quot;</span><span class="s">std::string</span> <span class="s">KernelSource_</span><span class="o">${</span><span class="nv">KERNEL</span><span class="o">}</span> <span class="s">=</span> <span class="s2">&quot; &gt;&gt; ${DST}</span>
</span><span class='line'><span class="s2">         COMMAND cat ${SRC} | sed &#39;s/\\\\/\\\\\\\\/g&#39; | sed &#39;s/\&quot;</span><span class="s">/\\\\\</span><span class="s2">&quot;/g&#39; | awk &#39;{ printf \(\&quot;</span><span class="s">\\&quot;%s\\\\n\\&quot;\\n\&quot;,</span> <span class="err">$$</span><span class="s">0\</span><span class="p">)</span> <span class="err">}&#39;</span> <span class="err">&gt;&gt;</span> <span class="err">${DST}</span>
</span><span class='line'>          <span class="err">COMMAND</span> <span class="err">echo</span> <span class="err">&quot;\;</span> <span class="err">}</span> <span class="err">}&quot;</span> <span class="err">&gt;&gt;</span> <span class="err">${DST}</span>
</span><span class='line'>          <span class="err">MAIN_DEPENDENCY</span> <span class="err">${SRC}</span>
</span><span class='line'>      <span class="err">)</span>
</span><span class='line'>  <span class="nb">ENDIF</span><span class="p">(</span><span class="s">WIN32</span><span class="p">)</span>
</span><span class='line'><span class="nb">ENDFUNCTION</span><span class="p">(</span><span class="s">PreprocessOCLKernel</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h2>CUDA-only Language Features</h2>

<p>Perhaps more important than tools are the capabilities of the language. Here are some notable ones that I encountered.</p>

<h3>Warp vote functions</h3>

<p>I found certain functions that were relied on in research (well, NVIDIA&rsquo;s graphics research group no less) did not have OpenCL analogues.</p>

<ul>
<li>__ballot(): Used in wavefront rendering to coalesce atomic increments to a queue count</li>
<li>__any(): Used by speculative ray traversal to help with execution coherence</li>
<li>__all()</li>
</ul>


<p><a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-vote-functions">See documentation here</a></p>

<p>It&rsquo;s not to say that these instructions cannot be implemented in OpenCL (they can with comparison to an atomic counter), and I&rsquo;m also not clear on how much performance benefit these functions bring, but it was something I encountered when trying to implement recent papers.</p>

<h3>Kernel C++ support</h3>

<p>You can write kernel traversal code in structs and classes. You can use some simple function templating, compare:</p>

<figure class='code'><figcaption><span>CUDA Swap</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span><span class='line'><span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">void</span> <span class="n">swap</span><span class="p">(</span><span class="n">T</span> <span class="o">&amp;</span><span class="n">x</span><span class="p">,</span> <span class="n">T</span> <span class="o">&amp;</span><span class="n">y</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="n">T</span> <span class="n">temp</span> <span class="o">=</span> <span class="n">x</span><span class="p">;</span>
</span><span class='line'>    <span class="n">x</span> <span class="o">=</span> <span class="n">y</span><span class="p">;</span>
</span><span class='line'>    <span class="n">y</span> <span class="o">=</span> <span class="n">temp</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>For OpenCL you&rsquo;d have to write a swap function per type&hellip;tedious:</p>

<figure class='code'><figcaption><span>OpenCL Swap</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="kt">void</span> <span class="nf">swap</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">y</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="kt">int</span> <span class="n">temp</span> <span class="o">=</span> <span class="o">*</span><span class="n">x</span><span class="p">;</span>
</span><span class='line'>    <span class="o">*</span><span class="n">x</span> <span class="o">=</span> <span class="o">*</span><span class="n">y</span><span class="p">;</span>
</span><span class='line'>    <span class="o">*</span><span class="n">y</span> <span class="o">=</span> <span class="n">temp</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Clean code with Thrust</h3>

<p>A benefit of the C++ support in CUDA is the thrust library. The idea and usage is pretty neat: use STL types to encapsulate information on where the data is stored, and provide functions as a way of operating on that data in a device/host agnostic way.</p>

<p>Here&rsquo;s an example of doing GPU programming in a STL, template friendly like manner.</p>

<figure class='code'><figcaption><span>Thrust Kernel Functor</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">struct</span> <span class="n">BVHTraverseFunctor</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="k">const</span> <span class="n">CudaBVHNode</span> <span class="o">*</span><span class="n">nodes</span><span class="p">;</span>
</span><span class='line'>    <span class="k">const</span> <span class="n">CudaTriangle</span> <span class="o">*</span><span class="n">leaves</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">BVHTraverseFunctor</span><span class="p">(</span><span class="k">const</span> <span class="n">CudaBVHNode</span> <span class="o">*</span><span class="n">nodes_</span><span class="p">,</span>
</span><span class='line'>                       <span class="k">const</span> <span class="n">CudaTriangle</span> <span class="o">*</span><span class="n">leaves_</span><span class="p">)</span> <span class="o">:</span>
</span><span class='line'>        <span class="n">nodes</span><span class="p">(</span><span class="n">nodes_</span><span class="p">),</span>
</span><span class='line'>        <span class="n">leaves</span><span class="p">(</span><span class="n">leaves_</span><span class="p">)</span>
</span><span class='line'>    <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>    <span class="cm">/**</span>
</span><span class='line'><span class="cm">     * @return (t, u, v, index) intersection</span>
</span><span class='line'><span class="cm">     */</span>
</span><span class='line'>    <span class="n">__host__</span> <span class="n">__device__</span> <span class="n">CudaIntersection</span> <span class="k">operator</span><span class="p">()(</span><span class="n">CudaRay</span> <span class="n">ray</span><span class="p">)</span>  <span class="cm">/* ((origin, tmin), (dest, tmax))  */</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="c1">// Perform ray traversal</span>
</span><span class='line'>        <span class="p">...</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">intersection</span><span class="p">;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using <code>thrust::device_vector</code> and <code>thrust::host_vector</code> allows for simpler and more maintainable code than managing raw buffer objects using <code>clCreateBuffer</code> or <code>cudaMalloc</code>. Assigning to a device vector from a host vector triggers a copy from host to device.</p>

<figure class='code'><figcaption><span>Host Code</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">class</span> <span class="nc">CudaTracer</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'><span class="k">private</span><span class="o">:</span>
</span><span class='line'>    <span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">CudaBVHNode</span><span class="o">&gt;</span> <span class="n">_gpu_bvh_nodes</span><span class="p">;</span>
</span><span class='line'>    <span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">CudaTriangle</span><span class="o">&gt;</span> <span class="n">_gpu_leaves</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">CudaRay</span><span class="o">&gt;</span> <span class="n">_gpu_rays</span><span class="p">;</span>
</span><span class='line'>    <span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">CudaIntersection</span><span class="o">&gt;</span> <span class="n">_gpu_hits</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="p">...</span>
</span><span class='line'><span class="p">};</span>
</span><span class='line'>
</span><span class='line'><span class="kt">void</span> <span class="n">CudaTracer</span><span class="o">::</span><span class="n">EnqueueRays</span><span class="p">(</span><span class="k">const</span> <span class="n">thrust</span><span class="o">::</span><span class="n">host_vector</span><span class="o">&lt;</span><span class="n">CudaRay</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">ray_buffer</span><span class="p">,</span>
</span><span class='line'>                             <span class="n">thrust</span><span class="o">::</span><span class="n">host_vector</span><span class="o">&lt;</span><span class="n">CudaIntersection</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">hit_buffer</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="c1">// Upload input to device</span>
</span><span class='line'>    <span class="n">_gpu_rays</span> <span class="o">=</span> <span class="n">ray_buffer</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Resize output array</span>
</span><span class='line'>    <span class="n">_gpu_hits</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">_gpu_rays</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Initialize functor with device pointers</span>
</span><span class='line'>    <span class="n">BVHTraverseFunctor</span> <span class="n">traverse_functor</span><span class="p">(</span><span class="n">raw_pointer_cast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">_gpu_bvh_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
</span><span class='line'>                                        <span class="n">raw_pointer_cast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">_gpu_leaves</span><span class="p">[</span><span class="mi">0</span><span class="p">]));</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Execute kernel via thrust</span>
</span><span class='line'>    <span class="n">thrust</span><span class="o">::</span><span class="n">transform</span><span class="p">(</span><span class="n">_gpu_rays</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
</span><span class='line'>                      <span class="n">_gpu_rays</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
</span><span class='line'>                      <span class="n">_gpu_hits</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
</span><span class='line'>                      <span class="n">traverse_functor</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Copy results back to host</span>
</span><span class='line'>    <span class="n">hit_buffer</span> <span class="o">=</span> <span class="n">_gpu_hits</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>If you have NVIDIA hardware, and you&rsquo;re looking to have a smooth, more well supported development experience, and you&rsquo;re not concerned about deploying/distributing to users who don&rsquo;t have NVIDIA hardware, use CUDA! In the meantime, I&rsquo;m hoping to see that OpenCL receive more support from NVIDIA.</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Calvin Hsu</span></span>

      








  


<time datetime="2013-12-06T14:01:48-08:00" pubdate data-updated="true">Dec 6<span>th</span>, 2013</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/cuda/'>CUDA</a>, <a class='category' href='/blog/categories/debugging/'>Debugging</a>, <a class='category' href='/blog/categories/gpgpu/'>GPGPU</a>, <a class='category' href='/blog/categories/opencl/'>OpenCL</a>, <a class='category' href='/blog/categories/tools/'>Tools</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://calvindhsu.github.io/blog/2013/12/06/cuda-vs-opencl/" data-via="" data-counturl="http://calvindhsu.github.io/blog/2013/12/06/cuda-vs-opencl/" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/12/05/project-reflections/" title="Previous Post: Project Reflections">&laquo; Project Reflections</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/12/06/cuda-vs-opencl/">CUDA vs OpenCL Development Experience on an NVIDIA GPU</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/05/project-reflections/">Project Reflections</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/03/debugging-variance/">Debugging Variance: Mistakes and Lessons</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Calvin Hsu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>. Design by <a href="http://octopressthemes.com">Octopress Themes</a>.</span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'visualoutput';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://calvindhsu.github.io/blog/2013/12/06/cuda-vs-opencl/';
        var disqus_url = 'http://calvindhsu.github.io/blog/2013/12/06/cuda-vs-opencl/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
