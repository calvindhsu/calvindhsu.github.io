<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Debugging | visual output]]></title>
  <link href="http://calvindhsu.github.io/blog/categories/debugging/atom.xml" rel="self"/>
  <link href="http://calvindhsu.github.io/"/>
  <updated>2013-12-09T17:19:33-08:00</updated>
  <id>http://calvindhsu.github.io/</id>
  <author>
    <name><![CDATA[Calvin Hsu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[CUDA vs OpenCL Development Experience on an NVIDIA GPU]]></title>
    <link href="http://calvindhsu.github.io/blog/2013/12/06/cuda-vs-opencl/"/>
    <updated>2013-12-06T14:01:48-08:00</updated>
    <id>http://calvindhsu.github.io/blog/2013/12/06/cuda-vs-opencl</id>
    <content type="html"><![CDATA[<p>I had to make a choice as to what GPGPU API to use for my GPU path tracer. I read sources like <a href="http://wiki.tiker.net/CudaVsOpenCL">CUDA Vs OpenCL: Which should I use</a> and decided initially that OpenCL would be the right choice: support an open standard which would see wider and wider adoption and gain experience with the API. However, I found along the way, the path of least resistance brought me to CUDA.</p>

<p>Big caveat here: I approached this choice as something to use for my personal, learning project with no need to ship a commercial product.</p>

<h3>What&rsquo;s inside my machine?</h3>

<p>I started out basing my choice off of the GPU I had already, since I wasn&rsquo;t ready to shell out money for a new card. Obviously if you have an AMD card there&rsquo;s no choice (also good luck if you want to develop on Linux, the drivers <a href="https://wiki.archlinux.org/index.php/AMD_Catalyst">are not well regarded by the community</a>).</p>

<p>So in my case I did have a choice with my 2 year old NVIDIA Geforce 560Ti (Fermi). This post documents experience with the tool support, build system, and language features.</p>

<!-- more -->


<h2>Tools</h2>

<p>GPU tool support has always been vendor specific i.e. Nsight vs CodeXL (previously gDebugger, AMD purchased Graphic Remedy), and FX Composer vs RenderMonkey. For GPGPU computing there&rsquo;s the additional factor that CUDA is NVIDIA&rsquo;s proprietary technology, and this appears to motivate some uneven support.</p>

<h3>NVIDIA Nsight (Eclipse Edition v5.5.0): CUDA only <a href="http://www.nvidia.com/object/nsight.html">Official Site</a></h3>

<p>NVIDIA Nsight doesn&rsquo;t have any support for OpenCL development. I&rsquo;ve only tested out the Eclipse edition at the time of this writing, and it lacks, well, everything:</p>

<ul>
<li>No OpenCL syntax highlighting</li>
<li>Inability to profile OpenCL calls / kernel performance</li>
<li>Inability to debug OpenCL kernels</li>
</ul>


<p>This was a pretty big disappointment, I was really looking forward to at least seeing some performance traces for my program. At least that would help reveal at a glance where the time is being spent (i.e. memory transfers, compute, CPU).</p>

<p><strong>Workaround: Lack of Syntax Highlighting</strong></p>

<p>Because OpenCL&rsquo;s C is similar, Google reveals that a lot of people end up designating cl files as C files, then creating a dummy header file that is included in .cl code, something like:</p>

<p>```c cl_ignores.h</p>

<h1>define __kernel</h1>

<h1>define __global</h1>

<h1>define __local</h1>

<h1>define __constant</h1>

<p>```</p>

<p><strong>Warning: CUDA kernel debugging requires 2 GPUs or SM3.5</strong></p>

<p>One unfortunate discovery was finding out that kernel debugging requires a 2nd GPU or a SM3.5+ GPU of which there are currently a handful of models. See <a href="http://www.youtube.com/watch?v=nKKLqc2TgsI">this demonstration</a>.</p>

<h3>AMD CodeXL <a href="http://developer.amd.com/tools-and-sdks/heterogeneous-computing/codexl/">Official Site</a></h3>

<p>I evaluated CodeXL for use with NVIDIA hardware on a Linux machine and it <em>does</em> log and report OpenCL calls and errors, but it is not able to debug or profile.</p>

<h3>CUDA only: printf support</h3>

<p>With an inability to use a debugger, one would naturally rely on print to log debug information. However, NVIDIA drivers only support OpenCL 1.1, so printf isn&rsquo;t supported. This support is enabled via vendor extensions, but I cannot find such an OpenCL extension for NVIDIA GPUs.</p>

<p>Funny enough (NVIDIA&rsquo;s priorities are not hidden), CUDA has this function built-in, and it works on the same hardware.</p>

<p><strong>Aside: Why is it important to have printf for GPU development?</strong></p>

<p>Some might argue: don&rsquo;t waste your time, printf isn&rsquo;t useful for debugging, you should write tests or examine that value of output when read back on the CPU.</p>

<p>I believe some of these opinions have to do with the noise of too many inputs. After all if you put in 1 printf into your kernel but your kernels runs 1k threads in parallel you will get so much extra data (Warning: don&rsquo;t do this with 1 GPU since you&rsquo;ll freeze up the driver!).</p>

<p>I argue that it&rsquo;s still useful provided you are able to limit your input sizes. This was a process that I used in my own development process: see a bad pixel, limit rendering to that 1 pixel, use printfs to output debug information to determine where GPU code was failing.</p>

<p>Combine that with the fact that GPU programs are becoming increasingly complicated. Aila &amp; Laine&rsquo;s purportedly state of the art <a href="https://code.google.com/p/understanding-the-efficiency-of-ray-traversal-on-gpus/">GPU ray traversal kernels</a> involves several nested while loops, a stack 32 frames deep, compact data structures with precomputed values. It would be extremely tedious to debug without having some sort of intermediate output besides ray hit / not-hit.</p>

<h3>Build support: CUDA compiles kernel code</h3>

<p>This not only makes you avoid the fuss of dealing with loading text from file and giving your errors at build time, but it makes it easier to share header files between host and device code. This is useful for declaring types that need to be passed between host and device in a shared header file.</p>

<p><strong>CUDA and C++11 with CMake</strong></p>

<p>In my project I encountered some complications with incorporating CUDA and C++11 code. The problem is that CUDA&rsquo;s host compiler is older, and won&rsquo;t compile the latest GCC 4.8 headers that are on my system. The solution is to separate CUDA code into a self contained library, and then link it with the main binary.</p>

<p>Recent versions of CMake already includes a FindCUDA.cmake library written by James Bigler. By default this will propagate your host compiler flags to the NVIDIA C++ compiler. If you&rsquo;re using <code>-std=c++11</code> then you might get an error like this:</p>

<pre><code>/opt/cuda/bin/nvcc /home/calvin/Projects/spbr/spbr/cudakernels/src/bvh_intersect.cu -c -o /home/calvin/Projects/spbr-build2/spbr/cudakernels/CMakeFiles/cudakernels.dir/src/./cudakernels_generated_bvh_intersect.cu.o -ccbin /usr/bin/cc -m64 -D__CL_ENABLE_EXCEPTIONS -Xcompiler ,\"-std=c++11\",\"-g\",\"-Wall\",\"-g\" --gpu-architecture sm_21 -DNVCC -I/opt/cuda/include -I/opt/cuda/include
/usr/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include/stddef.h(432): error: identifier "nullptr" is undefined

/usr/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include/stddef.h(432): error: expected a ";"

/usr/include/c++/4.8.2/x86_64-unknown-linux-gnu/bits/c++config.h(190): error: expected a ";"

/usr/include/c++/4.8.2/exception(63): error: expected a ";"

/usr/include/c++/4.8.2/exception(68): error: expected a ";"

/usr/include/c++/4.8.2/exception(76): error: expected a ";"

/usr/include/c++/4.8.2/exception(83): error: expected a ";"

/usr/include/c++/4.8.2/exception(93): error: expected a "{"
</code></pre>

<p>This is caused by the NVIDIA compiler (nvcc) getting c++11 flags and being able to compile the standard headers. To fix, add the following line to your <code>CMakeLists.txt</code></p>

<p><code>cmake Getting CUDA to compile with C++11 in CMake</code>
set(CUDA_PROPAGATE_HOST_FLAGS OFF)
```</p>

<p><strong>OpenCL Semi-workaround 1: Includes by prepending source strings</strong></p>

<p>You can get around lack of include support by prepending header files to your OpenCL source in your host code. But this also messy since then you need a build mechanism to include shared header files as text.</p>

<p><strong>OpenCL Semi-Workaround 2: Auto-convert cl source files to cpp string</strong></p>

<p>The guys who work on <a href="http://www.luxrender.net">Luxrender GPU</a> cleverly made their build system take *.cl files and insert them as strings in .cpp files. This nicety removes the pain of resource managing and loading files from source. Here&rsquo;s a CMake function from their build set-up:</p>

<p>```cmake KernelPreprocess.cmake <a href="http://www.luxrender.net">http://www.luxrender.net</a>
FUNCTION(PreprocessOCLKernel NAMESPACE KERNEL SRC DST)</p>

<pre><code>MESSAGE(STATUS "Preprocessing OpenCL kernel: " ${SRC} " =&gt; " ${DST} )

IF(WIN32)
    add_custom_command(
        OUTPUT ${DST}
        COMMAND echo "#include &lt;string&gt;" &gt; ${DST}
        COMMAND echo namespace ${NAMESPACE} "{ namespace ocl {" &gt;&gt; ${DST}
        COMMAND echo std::string KernelSource_PathOCL_${KERNEL} = &gt;&gt; ${DST}
</code></pre>

<h1>TODO: this code need to be update in order to replace &ldquo; char with \&rdquo; (i.e. sed &rsquo;s/&ldquo;/\&rdquo;/g')</h1>

<pre><code>        COMMAND for /F \"usebackq tokens=*\" %%a in (${SRC}) do echo \"%%a\\n\" &gt;&gt; ${DST}
        COMMAND echo "; } }" &gt;&gt; ${DST}
        MAIN_DEPENDENCY ${SRC}
    )
ELSE(WIN32)
    add_custom_command(
        OUTPUT ${DST}
        COMMAND echo \"\#include &lt;string&gt;\" &gt; ${DST}
        COMMAND echo namespace ${NAMESPACE} \"{ namespace ocl {\" &gt;&gt; ${DST}
        COMMAND echo "std::string KernelSource_${KERNEL} = " &gt;&gt; ${DST}
        COMMAND cat ${SRC} | sed 's/\\\\/\\\\\\\\/g' | sed 's/\"/\\\\\"/g' | awk '{ printf \(\"\\"%s\\\\n\\"\\n\", $$0\) }' &gt;&gt; ${DST}
        COMMAND echo "\; } }" &gt;&gt; ${DST}
        MAIN_DEPENDENCY ${SRC}
    )
ENDIF(WIN32)
</code></pre>

<p>ENDFUNCTION(PreprocessOCLKernel)
```</p>

<h2>CUDA-only Language Features</h2>

<p>Perhaps more important than tools are the capabilities of the language. Here are some notable ones that I encountered.</p>

<h3>Warp vote functions</h3>

<p>I found certain functions that were relied on in research (well, NVIDIA&rsquo;s graphics research group no less) did not have OpenCL analogues.</p>

<ul>
<li>__ballot(): Used in wavefront rendering to coalesce atomic increments to a queue count</li>
<li>__any(): Used by speculative ray traversal to help with execution coherence</li>
<li>__all()</li>
</ul>


<p><a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#warp-vote-functions">See documentation here</a></p>

<p>It&rsquo;s not to say that these instructions cannot be implemented in OpenCL (they can with comparison to an atomic counter), and I&rsquo;m also not clear on how much performance benefit these functions bring, but it was something I encountered when trying to implement recent papers.</p>

<h3>Kernel C++ support</h3>

<p>You can write kernel traversal code in structs and classes. You can use some simple function templating, compare:</p>

<p>```c++ CUDA Swap
template <typename T>
<strong>host</strong> <strong>device</strong> void swap(T &amp;x, T &amp;y)
{</p>

<pre><code>T temp = x;
x = y;
y = temp;
</code></pre>

<p>}
```</p>

<p>For OpenCL you&rsquo;d have to write a swap function per type&hellip;tedious:</p>

<p>```c OpenCL Swap
void swap(int <em>x, int </em>y)
{</p>

<pre><code>int temp = *x;
*x = *y;
*y = temp;
</code></pre>

<p>}
```</p>

<h3>Clean code with Thrust</h3>

<p>A benefit of the C++ support in CUDA is the thrust library. The idea and usage is pretty neat: use STL types to encapsulate information on where the data is stored, and provide functions as a way of operating on that data in a device/host agnostic way.</p>

<p>Here&rsquo;s an example of doing GPU programming in a STL, template friendly like manner.</p>

<p>```c++ Thrust Kernel Functor
struct BVHTraverseFunctor
{</p>

<pre><code>const CudaBVHNode *nodes;
const CudaTriangle *leaves;

BVHTraverseFunctor(const CudaBVHNode *nodes_,
                   const CudaTriangle *leaves_) :
    nodes(nodes_),
    leaves(leaves_)
{}

/**
 * @return (t, u, v, index) intersection
 */
__host__ __device__ CudaIntersection operator()(CudaRay ray)  /* ((origin, tmin), (dest, tmax))  */
{
    // Perform ray traversal
    ...
    return intersection;
}
</code></pre>

<p>}
```</p>

<p>Using <code>thrust::device_vector</code> and <code>thrust::host_vector</code> allows for simpler and more maintainable code than managing raw buffer objects using <code>clCreateBuffer</code> or <code>cudaMalloc</code>. Assigning to a device vector from a host vector triggers a copy from host to device.</p>

<p>```c++ Host Code
class CudaTracer
{
private:</p>

<pre><code>thrust::device_vector&lt;CudaBVHNode&gt; _gpu_bvh_nodes;
thrust::device_vector&lt;CudaTriangle&gt; _gpu_leaves;

thrust::device_vector&lt;CudaRay&gt; _gpu_rays;
thrust::device_vector&lt;CudaIntersection&gt; _gpu_hits;

...
</code></pre>

<p>};</p>

<p>void CudaTracer::EnqueueRays(const thrust::host_vector<CudaRay> &amp;ray_buffer,</p>

<pre><code>                         thrust::host_vector&lt;CudaIntersection&gt; &amp;hit_buffer)
</code></pre>

<p>{</p>

<pre><code>// Upload input to device
_gpu_rays = ray_buffer;

// Resize output array
_gpu_hits.resize(_gpu_rays.size());

// Initialize functor with device pointers
BVHTraverseFunctor traverse_functor(raw_pointer_cast(&amp;_gpu_bvh_nodes[0]),
                                    raw_pointer_cast(&amp;_gpu_leaves[0]));

// Execute kernel via thrust
thrust::transform(_gpu_rays.begin(),
                  _gpu_rays.end(),
                  _gpu_hits.begin(),
                  traverse_functor);

// Copy results back to host
hit_buffer = _gpu_hits;
</code></pre>

<p>}
```</p>

<h2>Conclusion</h2>

<p>If you have NVIDIA hardware, and you&rsquo;re looking to have a smooth, more well supported development experience, and you&rsquo;re not concerned about deploying/distributing to users who don&rsquo;t have NVIDIA hardware, use CUDA! In the meantime, I&rsquo;m hoping to see that OpenCL receive more support from NVIDIA.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debugging Variance: Mistakes and Lessons]]></title>
    <link href="http://calvindhsu.github.io/blog/2013/12/03/debugging-variance/"/>
    <updated>2013-12-03T17:40:00-08:00</updated>
    <id>http://calvindhsu.github.io/blog/2013/12/03/debugging-variance</id>
    <content type="html"><![CDATA[<p>My first entry will be dedicated to humbly pointing out some of the fun bugs I&rsquo;ve run into while working on my own path tracer. I didn&rsquo;t find many entries on steps used to debug variance, so I thought I&rsquo;d share my experiences here.</p>

<h3>The problem</h3>

<p>Consider the below output of the Cornell Box Scene:</p>

<p><a href="/images/posts/2013-12-03/noisy.png" class="fancybox" title="Noise and Artifacts "><img src="/images/posts/2013-12-03/noisy_m.png" alt="Noise and Artifacts " /></a></p>

<p>Some questions I kept asking myself:</p>

<ol>
<li>This is rendered with 1024 samples per pixel. Why is it so noisy?</li>
<li>This scene is simple and has dirac delta BRDFs (mirror), and plain old lambert. Why is it so noisy?</li>
<li>While interesting, where did that &ldquo;flower pedal&rdquo; light pattern on the ground come from?</li>
</ol>


<!-- more -->


<h3>Hypotheses and suspicions</h3>

<p>Initially I thought that the variance was caused by a bug in the integrator,
that I wasn&rsquo;t computing the pdf value correctly and properly weighting the
sample. Or it was a problem with the material evaluation and I wasn&rsquo;t computing
the bounce direction correctly.</p>

<p>Then I began to suspect the concentric uniform disk sampling code. At the start
of the project my partner and I thought it best to implement some of the
low-level routines ourselves to foster our understanding. We thought we could
write a simpler routine that would be clearer to us instead of borrowing the
code that was readily available. However, we hadn&rsquo;t tested it&rsquo;s correctness&hellip;
<em>it must be right</em> was our flaw.</p>

<p>We ignored it, and proceeded to generate many images. They all appeared too
noisy for the amount of samples we were taking. Being inexperienced, I thought,
maybe this was some efficiency issue, if we take more samples the noise will go
away.  However, published results kept showing cleaner images for the same
scene in &lt;= the # of samples per pixel.</p>

<h3>Debugging with pictures</h3>

<p>The best way to debug random sampling is with a picture, not with some routine that
measures the distribution. The human visual system is <em>superior at recognizing patterns</em>&hellip; given that you
feed a picture without too much information, after all the final image wasn&rsquo;t
helpful in pinpointing the problem.</p>

<p>Using alpha blending helped me to see if certain points overlapped more than
others. If the distribution was uniform, the color should be even.</p>

<p>``` c++ Plot the points with 10% alpha blending
void PlotPoint(int raster_width, int raster_height, const Point2 &amp;input, vector<Spectrum> &amp;pixels)
{</p>

<pre><code>int plot_width = raster_width / 2;
int plot_height = raster_height / 2;

Point2 p = input;
p.u = 0.5f * (p.u + 1.f);
p.v = 0.5f * (p.v + 1.f);

int x = roundf(plot_width * p.u + 0.5f * (raster_width - plot_width));
int y = roundf(plot_height * p.v + 0.5f * (raster_height - plot_height));

if (x &lt; 0 || y &lt; 0 || x &gt;= raster_width || y &gt;= raster_height)
{
    cout &lt;&lt; format("%f, %f") % p.u % p.v &lt;&lt; endl;
    return;
}

Spectrum &amp;target = pixels[x + raster_height * y];

Spectrum color(1.f, 0.f, 0.f);
float alpha = 0.1f;

target = alpha * color + (1.f - alpha) * target;
</code></pre>

<p>}
```</p>

<p>Taking a lot of samples is necessary to see a pattern (esp at 512x512 pixels), but too many and the image with coagulate into a solid blob</p>

<p>``` c++ Take 1M samples</p>

<pre><code>const int kNumSamples = 1 &lt;&lt; 20;
for (int i = 0; i &lt; kNumSamples; ++i)
{
    PlotPoint(kWidth, kHeight, ConcentricSampleDisk(rng.RandomFloat(), rng.RandomFloat()), pixels);
}
</code></pre>

<p>```</p>

<h3>Realization</h3>

<p><a href="/images/posts/2013-12-03/sampling_broken.png" class="fancybox" title="Large gaping holes, flower petal pattern "><img src="/images/posts/2013-12-03/sampling_broken_m.png" alt="Large gaping holes, flower petal pattern " /></a></p>

<p>Wow, so happy that I discovered this. All the samples are clumping around this flower petal pattern, and it&rsquo;s the same as our light pattern in the picture.</p>

<p><code>ConcentricSampleDisk</code> should take 2 floats ranging from [0, 1] and return them uniformly distributed in a 2D disk. This is based off of <a href="http://psgraphics.blogspot.com/2011/01/improved-code-for-concentric-map.html">Peter Shirley&rsquo;s original unit disk mapping</a>, which takes 4 triangle quadrants of a unit square to map to 45 degree slices of the unit disk. Our mapping was motivated by ideas similar to the simpler code posted by Shirley (divide into 2 quadrants), except that we decided to use tau as % half-lengths instead.</p>

<p>``` c++ Incorrect sampling
Point2 ConcentricSampleDisk(const float u1, const float u2)
{</p>

<pre><code>const float x = 2 * u1 - 1;
const float y = 2 * u2 - 1;

if (x == 0.f &amp;&amp; y == 0.f)
    return Point2(0.f, 0.f);

float tau;
const float r_x = fabs(x);
const float r_y = fabs(y);
float radius;
if (r_x &gt; r_y)
{
    const float tau_start = x &gt;= 0.f ? -0.25f : 0.75f;
    tau = u2 * 0.5f + tau_start;
    radius = r_x;
}
else
{
    const float tau_start = y &gt;= 0.f ? 0.25f : 1.25f;
    tau = u1 * 0.5f + tau_start;
    radius = r_y;
}
const float theta = tau * M_PI;
return Point2(radius * cos(theta), radius * sin(theta);
</code></pre>

<p>}
```</p>

<p>In lines 13, 19 we incorrectly redid this mapping as pick which sample is the
radius, which determines the tau_start, then use the other sample as the basis for the angle, theta.
However you&rsquo;ll notice there&rsquo;s an unforeseen dependency here, take the first
case for instance. If r_x is greater than r_y, then abs(u1) > abs(u2) and then
the range of values for u2 are strictly less than the abs(length). For this to work
u2 needs to be able to range from [0, 1], which is impossible given the if
condition.</p>

<h3>Solution</h3>

<p>The solution is to divide the two numbers. I hadn&rsquo;t realized it until this point, but this is more intuitive and probably is the motivation of the original code: the slope of the triangle maps directly to the angle. So obvious I feel dumb.</p>

<p>``` c++ Fixed code</p>

<pre><code>    tau = y/x * 0.5f + tau_start;
    tau = x/y * 0.5f + tau_start;
</code></pre>

<p>```</p>

<p>The new sampling code produces a uniformly distributed result.</p>

<p><a href="/images/posts/2013-12-03/sampling_correct.png" class="fancybox" title="Uniform! "><img src="/images/posts/2013-12-03/sampling_correct_m.png" alt="Uniform! " /></a></p>

<p>Which subsequently removed the noise and light artifacts</p>

<p><a href="/images/posts/2013-12-03/correct.png" class="fancybox" title="Smooth! "><img src="/images/posts/2013-12-03/correct_m.png" alt="Smooth! " /></a></p>

<h3>Takeaways</h3>

<ol>
<li>Take the time to write the visualization code for sampling routines. It took so little time and I wish I had done it sooner.</li>
<li>Reference images/scenes are a must for determining correctness. If I didn&rsquo;t have an idea of what an image with 1024 samples per pixel should look like, I would have a lot harder time convincing myself something was wrong.</li>
<li>Caution required before I implement someone else&rsquo;s technique, doing it better or making it clearer is not trivial. The context and motivation for each operation is often missing.</li>
</ol>

]]></content>
  </entry>
  
</feed>
